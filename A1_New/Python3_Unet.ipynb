{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np \n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.models import Sequential, Model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6],axis=3) \n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7],axis=3) \n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8],axis=3) \n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9],axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixing/.local/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "def combine_generator(gen1, gen2):\n",
    "    while True:\n",
    "        yield(gen1.next(), gen2.next())\n",
    "def myGenerator(train_generator,train_generator1):\n",
    "    while True:\n",
    "        xy = train_generator.next() #or next(train_generator)\n",
    "        xy1 = train_generator1.next() #or next(train_generator1)\n",
    "        yield (xy[0],xy1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Skin = [0,0,0]\n",
    "Unlabelled = [0,0,0]\n",
    "\n",
    "COLOR_DICT = np.array([Skin, Unlabelled])\n",
    "\n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255.0\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255.0\n",
    "        mask = mask /255.0\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "def trainGenerator(batch_size,aug_dict,image_color_mode = \"grayscale\",mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/train/image',\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = '/home/lixing/git/A1/data/train/aug',\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/train/label',\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = '/home/lixing/git/A1/data/train/aug_label',\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255.0\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixing/.local/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Found 36 images belonging to 1 classes.\n",
      "Found 36 images belonging to 1 classes.\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.7088 - acc: 0.0680\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.70882, saving model to unet_skin_detection.hdf5\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.6701 - acc: 0.9443\n",
      "\n",
      "Epoch 00002: loss improved from 0.70882 to 0.67007, saving model to unet_skin_detection.hdf5\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4638 - acc: 0.9706\n",
      "\n",
      "Epoch 00003: loss improved from 0.67007 to 0.46378, saving model to unet_skin_detection.hdf5\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2662 - acc: 0.9684\n",
      "\n",
      "Epoch 00004: loss improved from 0.46378 to 0.26621, saving model to unet_skin_detection.hdf5\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3344 - acc: 0.9669\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.26621\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3949 - acc: 0.9654\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.26621\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2451 - acc: 0.9658\n",
      "\n",
      "Epoch 00007: loss improved from 0.26621 to 0.24514, saving model to unet_skin_detection.hdf5\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3512 - acc: 0.9387\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.24514\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3292 - acc: 0.9614\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.24514\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3361 - acc: 0.9740\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.24514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5550b75e80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,data_gen_args)\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_skin_detection.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=1,epochs=10,callbacks=[model_checkpoint])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/test',\n",
    "        target_size=(256,256),\n",
    "        batch_size=1,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='binary')\n",
    "def testGenerator(test_generator):\n",
    "    while True:\n",
    "        xy = test_generator.next() #or next(train_generator)\n",
    "        yield (xy[0])\n",
    "test_image = testGenerator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixing/.local/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 1s/step\n"
     ]
    }
   ],
   "source": [
    "model_test = unet()\n",
    "model_test.load_weights(\"/home/lixing/git/A1/unet_skin_detection.hdf5\")\n",
    "results = model.predict_generator(test_image,10,verbose=1)\n",
    "saveResult(\"/home/lixing/git/A1/data/test\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255.0,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "seed= 1\n",
    "\n",
    "train_images_generator = train_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/train/image',\n",
    "        target_size=(256,256),\n",
    "        batch_size=1,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='binary',\n",
    "        save_to_dir='/home/lixing/git/A1/data/train/aug', \n",
    "        save_format='png',\n",
    "        seed=seed)\n",
    "train_masks_generator = train_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/train/label',\n",
    "        target_size=(256,256),\n",
    "        batch_size=1,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='binary',\n",
    "        save_to_dir='/home/lixing/git/A1/data/train/aug_label', \n",
    "        save_format='png',\n",
    "        seed=seed)\n",
    "\n",
    "validation_images_generator = train_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/validation/image_validation',\n",
    "        target_size=(256,256),\n",
    "        batch_size=1,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='binary',\n",
    "        seed=seed)\n",
    "\n",
    "validation_masks_generator = train_datagen.flow_from_directory(\n",
    "        '/home/lixing/git/A1/data/validation/label_validation',\n",
    "        target_size=(256,256),\n",
    "        batch_size=1,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='binary',\n",
    "        seed=seed)\n",
    "\n",
    "        \n",
    "combinedGenerator = myGenerator(train_images_generator, train_masks_generator)\n",
    "validation_generator = myGenerator(validation_images_generator,validation_masks_generator)\n",
    "history = model.fit_generator(\n",
    "        combinedGenerator,\n",
    "        steps_per_epoch=1,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
